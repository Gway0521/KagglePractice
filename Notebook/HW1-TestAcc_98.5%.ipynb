{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1 數字辨識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料處理\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 常用函數\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# 影像處理函數\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 分割資料\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# 資料集讀取和處理\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# 模型評估矩陣\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# 深度學習架構\n",
    "import torch\n",
    "from   torch import nn\n",
    "from   torch.optim import lr_scheduler, SGD, Adam\n",
    "\n",
    "# 調參數\n",
    "import optuna\n",
    "\n",
    "# transforms 時需要的函式(多執行緒需要另外把函數寫在 py 檔)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建資料夾\n",
    "dataset_path = '../Dataset/'\n",
    "if (not os.path.exists(dataset_path)):\n",
    "    os.mkdir(dataset_path)\n",
    "    print('創建 Dataset 資料夾')\n",
    "\n",
    "result_path = '../Result/'\n",
    "if (not os.path.exists(result_path)):\n",
    "    os.mkdir(result_path)\n",
    "    print('創建 Result 資料夾')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料分析與前處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作業給的資料集:\n",
    "- noisy_train_images.npy\n",
    "- noisy_train_labels.txt\n",
    "- test_images.npy\n",
    "\n",
    "為了方便之後的影像資料處理，我統一都用 numpy.ndarray 處理:\n",
    "- noisy_train_images.npy -> train_x\n",
    "- noisy_train_labels.txt -> train_y\n",
    "- test_images.npy -> test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x 讀取\n",
    "train_x = np.load('../Dataset/noisy_train_images.npy')\n",
    "\n",
    "# train_y 讀取並寫入 npy\n",
    "train_y = []\n",
    "with open('../Dataset/noisy_train_labels.txt', mode='r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        train_y.append(int(line.strip()))\n",
    "train_y = np.array(train_y)\n",
    "np.save('../Dataset/train_y.npy', train_y)\n",
    "\n",
    "# test_x 讀取\n",
    "test_x = np.load('../Dataset/test_images.npy')\n",
    "\n",
    "\n",
    "# 隨機顯示 20 張影像\n",
    "dataset = utils.NPDataset(train_x, train_y)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(20):\n",
    "    index = random.randint(0, len(dataset))\n",
    "    img, filtered_img, label = dataset[index]\n",
    "    plt.subplot(4, 10, i+1)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 從資料集 x 的 dimension 來看，可以知道訓練集有 60000 張，測試集有 10000 張，影像大小都是 28*28，灰階影像(通道數為1)。\n",
    "- 從訓練集 y 的 dimension 來看，可以知道每個 class 的儲存方式非 one-hot，有必要在訓練時轉為 one-hot。\n",
    "- 從訓練集各類別的分佈來看，可以知道數量上是蠻平均的，沒有必要做資料平衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('資料集 dimension:')\n",
    "print(f'train_x.shape: {train_x.shape}')\n",
    "print(f'train_y.shape: {train_y.shape}')\n",
    "print(f'test_x.shape:  {test_x.shape}')\n",
    "print('-'*30)\n",
    "\n",
    "print('資料集分佈:')\n",
    "class_distribution = [Counter(train_y)[i] for i in range(10)]\n",
    "print(f'Train: {class_distribution}')\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 影像前處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為分類任務的資料集使用的是含椒鹽雜訊的手寫數字影像，考慮到椒鹽雜訊可以輕鬆的使用中值濾波器去雜訊，因此 MLP 的預測除了輸入原始影像外，還會輸入經過 3*3 中值濾波後的影像。\n",
    "\n",
    "中值濾波處理我寫在 utils 裡面，NPDataset 會返回原始影像與濾波影像，其他處理都寫在 transforms.Compose 裡面。\n",
    "\n",
    "***\n",
    "- 資料集\n",
    "    - 訓練集：中值濾波器濾波後，進行裁切、旋轉、縮小(不放大，因為測試集沒有放大的數字)，最後做正歸化。\n",
    "    - 驗證集：為了保持影像與測試集一致，讓結果可以接近測試集，只做中值濾波器與普通的正歸化處理。\n",
    "- 影像處理\n",
    "    - 中值濾波器的 kernal 大小會影響到影像處理後的資訊，一般而言 kernal 越大，影像處理後所保留的資訊會越少，在經過比較和 trade off 後，採用 3\\*3 大小的 kernal。(2\\*2雜訊多，5\\*5丟失的資訊太多)\n",
    "    - 影像長寬隨機裁切 0 ~ 0.125 的比例，目的是為了平移影像，讓模型學習 \"當數字不在正中心\" 的情況。\n",
    "    - 影像隨機旋轉 0 ~ 30 度，讓模型學習 \"數字寫歪\" 的情況。\n",
    "    - 影像隨機(67%)縮小 1 ~ 1.5 (大小約 67%)，讓模型學習 \"數字較小\" 的情況。\n",
    "    - 影像正歸化，幫助模型訓練時可以更好收斂。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練集影像處理\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.v2.RandomAffine(degrees=30, translate=(0.125, 0.125)),   # 隨機裁切比例 0 ~ 0.125，隨機旋轉 0 ~ 30 度\n",
    "    transforms.v2.RandomZoomOut(fill=0, side_range=(1, 1.5), p=0.5),    # 隨機縮小 1 ~ 1.5 (大小約 67%)，補 0\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.v2.ToTensor(),                                           # 轉 Tensor，正歸化 (/255.)\n",
    "])\n",
    "# 驗證集影像處理\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.v2.ToTensor(),                                           # 轉 Tensor，正歸化 (/255.)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機挑選 20 張影像\n",
    "show_dataset = utils.NPDataset(train_x, train_y, transform=train_transform)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(20):\n",
    "    index = random.randint(0, len(show_dataset))\n",
    "    img, filtered_img, label = show_dataset[index]\n",
    "    plt.subplot(4, 10, i+1)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.imshow(img[0])\n",
    "    plt.subplot(4, 10, i+21)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.imshow(filtered_img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型架構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我使用的模型需要輸入原始影像與濾波影像，各自經過 MLP 後輸出串在一起，最後經過 MLP 後不接 Sigmoid 或 Softmax 輸出 10 個類別。其中除了輸出層外的 FC 使用 RELU 激勵函數。\n",
    "\n",
    "- original_hidden_size、filtered_hidden_size、combined_hidden_size、num_original_hidden、num_filtered_hidden 和 num_combined_hidden 由 optuna 用 貝葉斯搜尋 來找比較好的參數值。\n",
    "- 不接 Sigmoid 或 Softmax，因此在決定模型預測出來的類別該分類為何時，使用的是 torch.argmax(dim=1)，相當於找這 10 個類別中最大的輸出值在哪個 arg，就預測出哪個類別。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 GPU 跑\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# 模型架構\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size=28*28,\n",
    "                 num_classes=10,\n",
    "                 original_hidden_size=1024,\n",
    "                 filtered_hidden_size=1024,\n",
    "                 combined_hidden_size=1024,\n",
    "                 num_original_hidden=1,\n",
    "                 num_filtered_hidden=1,\n",
    "                 num_combined_hidden=1):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # 原始影像輸入與 MLP\n",
    "        self.original_layers = nn.ModuleList()\n",
    "        for i in range(num_original_hidden):\n",
    "            if i == 0:\n",
    "                self.original_layers.append(nn.Linear(input_size, original_hidden_size))\n",
    "            else:\n",
    "                self.original_layers.append(nn.Linear(original_hidden_size, original_hidden_size))\n",
    "            self.original_layers.append(nn.ReLU())\n",
    "\n",
    "        # 濾波影像輸入與 MLP\n",
    "        self.filtered_layers = nn.ModuleList()\n",
    "        for i in range(num_filtered_hidden):\n",
    "            if i == 0:\n",
    "                self.filtered_layers.append(nn.Linear(input_size, filtered_hidden_size))\n",
    "            else:\n",
    "                self.filtered_layers.append(nn.Linear(filtered_hidden_size, filtered_hidden_size))\n",
    "            self.filtered_layers.append(nn.ReLU())\n",
    "\n",
    "        # 結合層與 MLP\n",
    "        self.combined_layers = nn.ModuleList()\n",
    "        for i in range(num_combined_hidden):\n",
    "            if i == 0:\n",
    "                self.combined_layers.append(nn.Linear(original_hidden_size + filtered_hidden_size, combined_hidden_size))\n",
    "            else:\n",
    "                self.combined_layers.append(nn.Linear(combined_hidden_size, combined_hidden_size))\n",
    "            self.combined_layers.append(nn.ReLU())\n",
    "\n",
    "        # 分類\n",
    "        self.fc_output = nn.Linear(combined_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, original, filtered):\n",
    "        in1 = original.reshape(len(original), -1)\n",
    "        in2 = filtered.reshape(len(filtered), -1)\n",
    "\n",
    "        # 原始影像經過 MLP\n",
    "        for layer in self.original_layers:\n",
    "            in1 = layer(in1)\n",
    "\n",
    "        # 濾波影像經過 MLP\n",
    "        for layer in self.filtered_layers:\n",
    "            in2 = layer(in2)\n",
    "\n",
    "        # 結合兩層的輸出後送進 MLP\n",
    "        combined = torch.cat((in1, in2), dim=1)\n",
    "        for layer in self.combined_layers:\n",
    "            combined = layer(combined)\n",
    "\n",
    "        # 分類\n",
    "        out = self.fc_output(combined)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練函數與測試函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_model 單純訓練模型，輸出 acc_history, loss_history, best_model_wts, best_acc。\n",
    "- CV_train_model (5 次)交叉驗證，輸出 folds_result 包含每個 fold 的 acc_history, loss_history, best_model_wts, best_acc。\n",
    "- test_model 用模型預測，輸出 pred_list, label_list。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, scheduler, num_epochs):\n",
    "    '''\n",
    "    訓練模型，返回結果。\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    model: :class:`__main__.MLP`\n",
    "        模型本身。\n",
    "    dataloader: :class:`dict` `{string: torch.utils.data.dataloader.DataLoader}`\n",
    "        dataloader，應該要是一個 dict，裡面包含 train/val 的 dataloader {'train':train_dataloader, 'val':val_dataloader}。\n",
    "    criterion: :class:`torch.nn.modules.loss.CrossEntropyLoss`\n",
    "        Loss function。\n",
    "    optimizer: :class:`torch.optim.sgd.SGD`\n",
    "        優化器。\n",
    "    scheduler: :class:`torch.optim.lr_scheduler.CosineAnnealingWarmRestarts`\n",
    "        老實說我不知道 scheduler 要怎麼翻譯。\n",
    "    num_epochs: :class:`int`\n",
    "        訓練的 epochs 數。\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    acc_history: :class:`dict` `{string: list{float}}`\n",
    "        train 和 val 的 Accuracy 曲線。\n",
    "    loss_history: :class:`dict` `{string: list{float}}`\n",
    "        train 和 val 的 Loss 曲線。\n",
    "    best_model_wts: :class:`collections.OrderedDict`\n",
    "        val accuracy 最高的 model 的 state_dict。\n",
    "    best_acc: :class:`float`\n",
    "        最高的 val accuracy。\n",
    "    '''\n",
    "    acc_history = {'train' : [], 'val' : []}\n",
    "    loss_history = {'train' : [], 'val' : []}\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # 每一個 epoch\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(f'Epoch:{epoch}' + '-'*25)\n",
    "    \n",
    "        # 每一個 epoch 跑一次 train 和 val\n",
    "        for phase in ['train', 'val']:\n",
    "\n",
    "            # 根據 phase 決定模型的模式\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            # 計算 acc 和 loss 的變數\n",
    "            running_correct = 0\n",
    "            running_loss = 0.0\n",
    "            totalIm = 0\n",
    "\n",
    "            # 每一個 batch\n",
    "            for img, filtered_img, _label in tqdm(dataloader[phase], total=len(dataloader[phase]), leave=False, position=0):\n",
    "                \n",
    "                # 把 label 轉成獨熱編碼\n",
    "                label = torch.stack([nn.functional.one_hot(x, 10) for x in _label]).float()\n",
    "                totalIm += len(label)\n",
    "\n",
    "                # 單個 batch 預測結果、平均 loss 值\n",
    "                img = img.to(device)\n",
    "                filtered_img = filtered_img.to(device)\n",
    "                label = label.to(device)\n",
    "                _out = model(img, filtered_img)\n",
    "                loss = criterion(_out, label)\n",
    "\n",
    "                # 如果是 train，要反向傳播並更新權重\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 把預測結果和標籤從 10 個 output 轉成單個 output\n",
    "                pred = _out.argmax(dim=1)\n",
    "                label = label.argmax(dim=1)\n",
    "                # 計算單個 batch 的總 correct 和總 loss\n",
    "                running_correct += (pred == label).sum().item()\n",
    "                running_loss += loss.item() * len(label)\n",
    "            \n",
    "            # 計算單個 epoch 的 acc 和 loss\n",
    "            epoch_acc = running_correct / totalIm\n",
    "            epoch_loss = running_loss / totalIm\n",
    "            acc_history[phase].append(epoch_acc)\n",
    "            loss_history[phase].append(epoch_loss)\n",
    "\n",
    "            print(f\"{phase:<5}  acc.:{epoch_acc:.4f}  loss:{epoch_loss:.4f}\")\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('best acc. in val!')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return acc_history, loss_history, best_model_wts, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_train_model(_model, dataset, criterion, create_optimizer, create_scheduler, num_epochs=128, num_folds=5):\n",
    "    '''\n",
    "    交叉驗證，返回每個 Fold 的結果。\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    _model: :class:`__main__.MLP`\n",
    "        模型本身。\n",
    "    dataset: :class:`utils.NPDataset`\n",
    "        繼承 Dataset 的 NPDataset，裡面要有所有的 train_x 和 train_y，在 CV_train_model 裡會再切成 Fold。\n",
    "    criterion: :class:`torch.nn.modules.loss.CrossEntropyLoss`\n",
    "        Loss function。\n",
    "    create_optimizer: :class:`function`->`torch.optim.sgd.SGD`\n",
    "        返回優化器的函數。\n",
    "    create_scheduler: :class:`function`->`torch.optim.lr_scheduler.CosineAnnealingWarmRestarts`\n",
    "        返回 scheduler 的函數，我還是不知道 scheduler 要怎麼翻譯。\n",
    "    num_epochs: :class:`int`\n",
    "        訓練的 epochs 數。\n",
    "    num_folds: :class:`int`\n",
    "        交叉驗證的 Fold 數量。\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    folds_result: :class:`list`\n",
    "        包含每個 fold 的：\n",
    "        acc_history: :class:`dict` `{string: list{float}}`\n",
    "            train 和 val 的 Accuracy 曲線。\n",
    "        loss_history: :class:`dict` `{string: list{float}}`\n",
    "            train 和 val 的 Loss 曲線。\n",
    "        best_model_wts: :class:`collections.OrderedDict`\n",
    "            val accuracy 最高的 model 的 state_dict。\n",
    "        best_acc: :class:`float`\n",
    "            最高的 val accuracy。\n",
    "    '''\n",
    "    # 資料集分割\n",
    "    Kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    Kf_idx = Kf.split(dataset)\n",
    "\n",
    "    folds_result = []\n",
    "\n",
    "    # 每一個 fold\n",
    "    for fold, (train_index, val_index) in enumerate(Kf_idx):\n",
    "        print(f'Fold {fold + 1}')\n",
    "        \n",
    "        # 初始化模型\n",
    "        model = copy.deepcopy(_model)\n",
    "        optimizer = create_optimizer(model)\n",
    "        scheduler = create_scheduler(optimizer)\n",
    "\n",
    "        train_dataset = utils.NPDataset(train_x, train_y, train_transform)\n",
    "        val_dataset = utils.NPDataset(train_x, train_y, val_transform)\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_index)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_index)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64, sampler=train_subsampler, pin_memory=True, num_workers=2)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=64, sampler=val_subsampler, pin_memory=True, num_workers=2)\n",
    "        dataloader = {'train' : train_dataloader, 'val' : val_dataloader}\n",
    "\n",
    "        acc_hist, loss_hist, model_wts, best_acc = train_model(model, dataloader, criterion, optimizer, scheduler, num_epochs)\n",
    "        folds_result.append((acc_hist, loss_hist, model_wts, best_acc))\n",
    "\n",
    "    return folds_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    '''\n",
    "    Parameters\n",
    "    -----------\n",
    "    model: :class:`__main__.MLP`\n",
    "        模型本身。\n",
    "    dataloader: :class:`torch.utils.data.dataloader.DataLoader`\n",
    "        應該要是 val_dataloader。\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    pred_list: :class:`list` `{torch.Tensor}`\n",
    "        pred 的結果的 list。\n",
    "    label_list: :class:`list` `{torch.Tensor}`\n",
    "        label 的結果的 list。\n",
    "    '''\n",
    "    model.eval()\n",
    "\n",
    "    running_correct = 0\n",
    "    totalIm = 0\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for img, filtered_img, label in dataloader:\n",
    "        label = torch.stack([nn.functional.one_hot(x, 10) for x in label]).float()\n",
    "        totalIm += len(label)\n",
    "        img = img.to(device)\n",
    "        filtered_img = filtered_img.to(device)\n",
    "        label = label.to(device)\n",
    "        out = model(img, filtered_img)\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        label = label.argmax(dim=1)\n",
    "        running_correct += (pred == label).sum().item()\n",
    "        pred_list.extend(pred.to('cpu'))\n",
    "        label_list.extend(label.to('cpu'))\n",
    "    \n",
    "    acc = running_correct / totalIm\n",
    "    print(f\"val acc.:{acc:.4f}\")\n",
    "    return pred_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 調參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 5-Fold Cross Validation 的 Fold 1 作為資料集，以驗證時的 Validation Accuracy 作為調參數好壞的指標，使用 optuna 調各種參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集\n",
    "train_x = np.load('../Dataset/noisy_train_images.npy')\n",
    "train_y = np.load('../Dataset/train_y.npy')\n",
    "\n",
    "# 用 NPDataset 從 Numpy 形式的資料讀取影像和標籤，並且在取得影像時使用 transform\n",
    "train_dataset = utils.NPDataset(train_x, train_y, train_transform)\n",
    "val_dataset = utils.NPDataset(train_x, train_y, val_transform)\n",
    "\n",
    "# 分割資料集\n",
    "# 只跑一個 Fold 的話，固定跑 \"5-Fold Cross Validation 且 random_state=42\" 的 Fold 1\n",
    "Kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "Kf_idx = Kf.split(train_dataset)\n",
    "train_index, val_index = list(Kf_idx)[0]    # Fold 1 的切法\n",
    "train_subsampler = torch.utils.data.SubsetRandomSampler(train_index)\n",
    "val_subsampler = torch.utils.data.SubsetRandomSampler(val_index)\n",
    "\n",
    "# 用 DataLoader 控制 batch size，用 num_workers 做多執行緒處理，pin_memory 加速資料從 CPU 移到 GPU 的速度\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, sampler=train_subsampler, pin_memory=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, sampler=val_subsampler, pin_memory=True, num_workers=2)\n",
    "dataloader = {'train':train_dataloader, 'val':val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型固定參數\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "epoch_num = 35\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def objective(trial):\n",
    "    # 尋找較好的 learning rate\n",
    "    lr = trial.suggest_loguniform('lr', 0.1, 0.9)\n",
    "\n",
    "    # 尋找 hidden_size 和 num_hidden\n",
    "    original_hidden_size = trial.suggest_int('original_hidden_size', 256, 4096)\n",
    "    filtered_hidden_size = trial.suggest_int('filtered_hidden_size', 256, 4096)\n",
    "    combined_hidden_size = trial.suggest_int('combined_hidden_size', 256, 4096)\n",
    "    num_original_hidden = trial.suggest_int('num_original_hidden', 1, 5)\n",
    "    num_filtered_hidden = trial.suggest_int('num_filtered_hidden', 1, 5)\n",
    "    num_combined_hidden = trial.suggest_int('num_combined_hidden', 1, 5)\n",
    "\n",
    "    # 創建一個新的模型\n",
    "    model = MLP(input_size, num_classes, original_hidden_size, filtered_hidden_size, combined_hidden_size, num_original_hidden, num_filtered_hidden, num_combined_hidden).to(device)\n",
    "\n",
    "    # 使用建議的參數創建一個新的優化器\n",
    "    optimizer = SGD(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=0)\n",
    "\n",
    "    # 訓練模型並返回驗證集上的準確度\n",
    "    acc_hist, loss_hist, model_wts, best_acc = train_model(model, dataloader, criterion, optimizer, scheduler, epoch_num)\n",
    "    return best_acc\n",
    "\n",
    "# 創建一個學習器\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# 優化目標函數\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"最佳的參數是：\", study.best_params)\n",
    "print(\"最佳的試驗是：\", study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold 交叉驗證"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我把題目給的訊練集做 5-Fold Cross Validation，除了能更準確的反映出模型的效能外，也避免資料集之間的偏差。\n",
    "***\n",
    "- 關於資料集分割\n",
    "    - 為了避免其他人沒辦法復現出相同的結果，我統一使用 random_state=42 來打亂資料集，再進行分割。\n",
    "    - 不過雖然資料集相同，在模型訓練時使用的影像處理仍然有隨機的因素，因此不保證能訓練出一模一樣的結果。\n",
    "\n",
    "- 關於訓練參數\n",
    "    - Scheduler 用 CosineAnnealingWarmRestarts，T_0=5、T_mult=3、eta_min=0，也有試過 CosineAnnealingLR，T_max=32、eta_min=0 和 StepLR，效果上來說 CosineAnnealingWarmRestarts 最好，但老實說 CosineAnnealingLR 和 StepLR 如果調的好，效果也不會差到哪裡去。\n",
    "    - CosineAnnealingWarmRestarts 的退火週期公式是 (T_mult^0 + T_mult^1 + ... + T_mult^n) * T_0\n",
    "    - Epoch 數量是 200，這是因為要讓 CosineAnnealingWarmRestarts 能以 T_0=5、T_mult=3 的情況下完整跑完 4 次的餘弦退火。\n",
    "    - Loss Function 用 CrossEntropyLoss，沒什麼好說的，多分類任務常用的損失函數。\n",
    "    - Optimizer 用 SGD，有使用過 Adam，效果差不多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集\n",
    "train_x = np.load('../Dataset/noisy_train_images.npy')\n",
    "train_y = np.load('../Dataset/train_y.npy')\n",
    "\n",
    "# 模型參數\n",
    "epoch_num = 200\n",
    "\n",
    "original_hidden_size = study.best_params['original_hidden_size']\n",
    "filtered_hidden_size = study.best_params['filtered_hidden_size']\n",
    "combined_hidden_size = study.best_params['combined_hidden_size']\n",
    "num_original_hidden = study.best_params['num_original_hidden']\n",
    "num_filtered_hidden = study.best_params['num_filtered_hidden']\n",
    "num_combined_hidden = study.best_params['num_combined_hidden']\n",
    "\n",
    "model = MLP(input_size, num_classes, original_hidden_size, filtered_hidden_size, combined_hidden_size, num_original_hidden, num_filtered_hidden, num_combined_hidden).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def create_optimizer(model):\n",
    "    return SGD(model.parameters(), lr=study.best_params['lr'])\n",
    "def create_scheduler(optim):\n",
    "    return lr_scheduler.CosineAnnealingWarmRestarts(optim, T_0=5, T_mult=3, eta_min=0)\n",
    "    # 5 20 65 200\n",
    "\n",
    "cv_dataset = utils.NPDataset(train_x, train_y)\n",
    "folds_result = CV_train_model(model, cv_dataset, criterion, create_optimizer, create_scheduler, epoch_num, num_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy曲線 和 Loss曲線\n",
    "- 混淆矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畫出 acc 曲線和 loss 曲線\n",
    "\n",
    "for fold, (acc_hist, loss_hist, model_wts, best_acc) in enumerate(folds_result):\n",
    "    fig = plt.figure(figsize=(8, 3.34))\n",
    "    print(f'Fold {fold+1} acc. = {best_acc:.4f}')\n",
    "\n",
    "    for i, (name, curve) in enumerate({'Accuracy':acc_hist, 'Loss':loss_hist}.items()):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.plot(range(epoch_num), curve['train'], label = 'train')\n",
    "        plt.plot(range(epoch_num), curve['val'], label = 'val')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.title(f'Fold: {fold+1}  {name} Curve')\n",
    "\n",
    "    plt.savefig(f'../Result/curve_fold{fold+1}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畫出驗證集的混淆矩陣\n",
    "\n",
    "num_folds = 5\n",
    "val_dataset = utils.NPDataset(train_x, train_y, val_transform)\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    Kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    Kf_idx = Kf.split(cv_dataset)\n",
    "    train_index, val_index = list(Kf_idx)[fold]\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_index)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=64, sampler=val_subsampler, pin_memory=True, num_workers=2)\n",
    "    model.load_state_dict(folds_result[fold][2])\n",
    "    val_pred, val_label = test_model(model, val_dataloader)\n",
    "\n",
    "    cm = confusion_matrix(val_label, val_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n",
    "    disp.plot()\n",
    "    plt.savefig(f'../Result/confusion_matrix_fold{fold+1}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試集結果儲存到 CSV 檔\n",
    "\n",
    "test_x = np.load('C:/Users/Landis/Desktop/HW1/Dataset/test_images.npy')\n",
    "test_x_img = []\n",
    "test_x_filtered_img = []\n",
    "\n",
    "for i in range(test_x.shape[0]):\n",
    "    img = test_x[i]\n",
    "    filtered_img = np.array(utils.MedianFilter()(test_x[i]))\n",
    "    blank_img = np.zeros_like(img)\n",
    "    combined_image = np.stack((img, filtered_img, blank_img), axis=-1)\n",
    "\n",
    "    transformed_image = val_transform(Image.fromarray(combined_image))\n",
    "    img, filtered_img, _ = torch.split(transformed_image, 1, dim=0)\n",
    "\n",
    "    test_x_img.append(img)\n",
    "    test_x_filtered_img.append(filtered_img)\n",
    "test_x_img = torch.stack(test_x_img)\n",
    "test_x_filtered_img = torch.stack(test_x_filtered_img)\n",
    "\n",
    "for fold in range(5):\n",
    "    model.load_state_dict(folds_result[fold][2])\n",
    "\n",
    "    model.eval()\n",
    "    test_pred = model(test_x_img.to(device), test_x_filtered_img.to(device)).argmax(dim=1).cpu()\n",
    "\n",
    "    df = pd.DataFrame({\"SID\":range(10000), \"Number\":test_pred})\n",
    "    df.to_csv(f\"../Result/result_fold{fold+1}.csv\", index=False)\n",
    "\n",
    "    # 儲存模型\n",
    "    torch.save(model.state_dict(), f\"../Result/result_fold{fold+1}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
